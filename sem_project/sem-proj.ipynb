{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7202286,"sourceType":"datasetVersion","datasetId":4157922}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pymorphy2\n!pip install pymystem3","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:06:02.619447Z","iopub.execute_input":"2023-12-17T17:06:02.620134Z","iopub.status.idle":"2023-12-17T17:06:28.362102Z","shell.execute_reply.started":"2023-12-17T17:06:02.620095Z","shell.execute_reply":"2023-12-17T17:06:28.360981Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pymorphy2\n  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\nCollecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: docopt>=0.6 in /opt/conda/lib/python3.10/site-packages (from pymorphy2) (0.6.2)\nInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\nSuccessfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\nCollecting pymystem3\n  Downloading pymystem3-0.2.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pymystem3) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pymystem3) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pymystem3) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pymystem3) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pymystem3) (2023.11.17)\nInstalling collected packages: pymystem3\nSuccessfully installed pymystem3-0.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n# from razdel import tokenize\nfrom nltk.corpus import stopwords\nimport nltk\nfrom bs4 import BeautifulSoup\nimport os\nfrom tqdm import tqdm\nimport re\nfrom pymystem3 import Mystem\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport torch\nimport torch.nn.functional as f\n\nfrom transformers import AutoModel, AutoTokenizer\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:06:28.364612Z","iopub.execute_input":"2023-12-17T17:06:28.365011Z","iopub.status.idle":"2023-12-17T17:06:35.014783Z","shell.execute_reply.started":"2023-12-17T17:06:28.364970Z","shell.execute_reply":"2023-12-17T17:06:35.013683Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"docs_titles = pd.read_table('/kaggle/input/1sem-project/anomaly-detection-competition-ml1-ts-autumn-2023/docs_titles.tsv')\ntrain_data = pd.read_csv('/kaggle/input/1sem-project/anomaly-detection-competition-ml1-ts-autumn-2023/train_groups.csv')\ntexts_from_bodies_part1 = pd.read_csv('/kaggle/input/1sem-project/some_lemm_data.csv')\ntexts_from_bodies_part2 = pd.read_csv('/kaggle/input/1sem-project/some_lemm_data_part_2.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-17T17:06:35.016190Z","iopub.execute_input":"2023-12-17T17:06:35.017563Z","iopub.status.idle":"2023-12-17T17:08:01.453691Z","shell.execute_reply.started":"2023-12-17T17:06:35.017516Z","shell.execute_reply":"2023-12-17T17:08:01.452745Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ids = train_data[train_data['group_id'] == 1]['doc_id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx in ids:\n    f = open(f'/kaggle/input/1sem-project/content/content/{idx}.dat')\n\n    soup_page = BeautifulSoup(f, 'html.parser')\n    try:\n        print(soup_page.find(\"meta\", attrs={\"name\":\"description\"}).get('content'))\n    except:\n        print(None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts_from_bodies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"docs_titles","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"docs_titles","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_data[train_data['group_id'] == 2]['doc_id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titles = []\n\nfor idx in train_data['doc_id']:\n    titles.append(docs_titles[docs_titles['doc_id'] == idx])\n\nprint(len(titles))\ntrain_data['title'] = titles","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install razdel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('stopwords')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def checkExecTimeMystemOneText(texts):\n#     mystem = Mystem()\n#     stopwords_rus = stopwords.words(\"russian\")\n#     lol = lambda lst, sz: [lst[i:i+sz] for i in range(0, len(lst), sz)]\n#     txtpart = lol(texts, 1000)\n#     res = []\n#     for txtp in tqdm(txtpart):\n#         alltexts = ' '.join([str(txt) + ' br ' for txt in txtp])\n\n#         words = mystem.lemmatize(alltexts)\n#         doc = []\n#         for txt in words:\n#             if txt != '\\n' and txt.strip() != '' and txt not in stopwords_rus:\n#                 if txt == 'br':\n#                     res.append(doc)\n#                     doc = []\n#                 else:\n#                     doc.append(txt)\n    \n#     return res\n\n# lemm_text = checkExecTimeMystemOneText(texts_from_bodies['text'].to_numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts_from_bodies = texts_from_bodies.fillna('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# morph = Mystem()\n\n# stopwords_rus = stopwords.words(\"russian\")\n\n# tokenized_text = []\n\n# for text in tqdm(texts_from_bodies['text'].to_numpy()[15672:]):\n\n#     tokens = morph.lemmatize(str(text))\n#     tokens_complete = []\n\n#     for token in tokens:\n#         if token not in stopwords_rus and len(token) > 2 and token != '\\n' and token.strip() != '':\n#             tokens_complete.append(token)\n\n#     tokenized_text.append(tokens_complete)\n\n# # texts_from_bodies['text'] = tokenized_text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# idxs = texts_from_bodies['doc_id'].to_numpy()[15672:]\n# len(tokenized_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# some_lemm_data = pd.DataFrame({'doc_id': idxs, 'lemm_tokens': tokenized_text})\n# some_lemm_data.to_csv('some_lemm_data_part_2.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Код для загрузки текста из body**","metadata":{}},{"cell_type":"code","source":"# def upload_docs_group(dir_name='/kaggle/input/1sem-project/content/content'):\n# #     soup_pages = {}\n#     pattern = re.compile(r'[^А-я.]')\n#     text_from_body = []\n#     idxs = []\n    \n#     for doc_id in tqdm(os.listdir(dir_name)):\n#         f = open(f'{dir_name}/{doc_id}', 'r')\n        \n#         soup_page = BeautifulSoup(f, 'html.parser')\n        \n#         document_text = ''\n#         if soup_page.body:\n#             for item in soup_page.body.stripped_strings:\n#                 tokens_counter = len(item.split(' '))\n\n#                 item = re.sub(pattern,' ', item)\n\n\n#                 if tokens_counter > 3:\n#                     document_text += item + ' '\n\n#             document_text = re.sub(' +', ' ', document_text)\n\n#             text_from_body.append(document_text)\n        \n#         else:\n#             text_from_body.append('')\n        \n#         idxs.append(int(doc_id.split('.')[0]))\n    \n#     text_from_body = pd.DataFrame({'doc_id': idxs, 'text': text_from_body})\n#     text_from_body.to_csv('texts_from_bodies_all.csv', index=False)\n    \n# #     return soup_pages\n\n# upload_docs_group()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/working/texts_from_bodies_all.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['doc_id'] == 27577]['text'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def body_text_to_csv(soup_files):\n#     text_from_body = []\n#     pattern = re.compile(r'[^А-я]')\n#     idxs = []\n#     for key, value in tqdm(soup_files.items()):\n#         document_text = ''\n#         if soup_files[key].body:\n#             for item in soup_files[key].body.stripped_strings:\n#                 tokens_counter = len(item.split(' '))\n\n#                 item = re.sub(pattern,' ', item)\n\n\n#                 if tokens_counter > 3:\n#                     document_text += item + ' '\n\n#             document_text = re.sub(' +', ' ', document_text)\n\n#             text_from_body.append(document_text)\n        \n#         else:\n#             text_from_body.append('')\n        \n#         idxs.append(key)\n    \n#     text_from_body = pd.DataFrame({'doc_id': idxs, 'text': text_from_body})\n#     text_from_body.to_csv('texts_from_bodies.csv', index=False)\n    \n\n# body_text_to_csv(soup_files)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Similarity with Bert**","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\nmodel = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_for_bert_test = []\nfor idx in train_data[train_data['group_id'] == 1]['doc_id']:\n    text_for_bert_test.append(docs_titles[docs_titles['doc_id'] == idx]['title'].to_numpy()[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_for_bert_test = text_for_bert_test[:40]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.eval()\nmodel = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encodings = tokenizer(\n    text_for_bert_test,\n    padding=True,\n    return_tensors='pt'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encodings = encodings.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    embeds = model(**encodings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize(distances, figsize=(50, 5), titles=None):\n    # get the number of columns\n    ncols = len(distances)\n    # create the subplot placeholders\n    fig, ax = plt.subplots(ncols=ncols, figsize=figsize)\n    \n    for i in range(ncols):\n        \n        # get the axis in which we will draw the matrix\n        axes = ax[i] if ncols > 1 else ax\n        \n        # get the i-th distance\n        distance = distances[i]\n        \n        # create the heatmap\n        axes.imshow(distance)\n        \n        # show the ticks\n        axes.set_xticks(np.arange(distance.shape[0]))\n        axes.set_yticks(np.arange(distance.shape[1]))\n        \n        # set the tick labels\n        axes.set_xticklabels(np.arange(distance.shape[0]))\n        axes.set_yticklabels(np.arange(distance.shape[1]))\n        \n        # set the values in the heatmap\n        for j in range(distance.shape[0]):\n            for k in range(distance.shape[1]):\n                text = axes.text(k, j, str(round(distance[j, k], 3)),\n                               ha=\"center\", va=\"center\", color=\"w\")\n        \n        # set the title of the subplot\n        title = titles[i] if titles and len(titles) > i else \"Text Distance\"\n        axes.set_title(title, fontsize=\"x-large\")\n        \n    fig.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeds = embeds[0]\nCLSs = embeds[:, 0, :]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normalized = f.normalize(CLSs, p=2, dim=1)\ncls_dist = normalized.matmul(normalized.T)\ncls_dist = cls_dist.new_ones(cls_dist.shape) - cls_dist\ncls_dist = cls_dist.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize([cls_dist], titles=[\"CLS\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LDA**","metadata":{}},{"cell_type":"code","source":"texts_from_bodies = pd.concat([texts_from_bodies_part1, texts_from_bodies_part2]).drop(columns=['Unnamed: 0'])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T00:47:30.576302Z","iopub.execute_input":"2023-12-15T00:47:30.576733Z","iopub.status.idle":"2023-12-15T00:47:30.602617Z","shell.execute_reply.started":"2023-12-15T00:47:30.576693Z","shell.execute_reply":"2023-12-15T00:47:30.601498Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-12-15T00:47:30.603946Z","iopub.execute_input":"2023-12-15T00:47:30.604308Z","iopub.status.idle":"2023-12-15T00:47:30.623009Z","shell.execute_reply.started":"2023-12-15T00:47:30.604276Z","shell.execute_reply":"2023-12-15T00:47:30.621905Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       pair_id  group_id  doc_id  target\n0            1         1   15731       0\n1            2         1   14829       0\n2            3         1   15764       0\n3            4         1   17669       0\n4            5         1   14852       0\n...        ...       ...     ...     ...\n11685    11686       129   26672       0\n11686    11687       129   25838       0\n11687    11688       129   25703       0\n11688    11689       129   27885       0\n11689    11690       129   27987       0\n\n[11690 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pair_id</th>\n      <th>group_id</th>\n      <th>doc_id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>15731</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>14829</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>15764</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>17669</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>14852</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11685</th>\n      <td>11686</td>\n      <td>129</td>\n      <td>26672</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11686</th>\n      <td>11687</td>\n      <td>129</td>\n      <td>25838</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11687</th>\n      <td>11688</td>\n      <td>129</td>\n      <td>25703</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11688</th>\n      <td>11689</td>\n      <td>129</td>\n      <td>27885</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11689</th>\n      <td>11690</td>\n      <td>129</td>\n      <td>27987</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>11690 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_texts_from_bodies = []\n\nfor item in train_data['doc_id']:\n    t = texts_from_bodies[texts_from_bodies['doc_id'] == item]['lemm_tokens'].to_numpy()[0]\n    t = t.replace('[', '')\n    t = t.replace(']', '')\n    t = t.replace(\"'\", '')\n    t = t.split(',')\n    train_texts_from_bodies.append(t)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T00:47:30.624345Z","iopub.execute_input":"2023-12-15T00:47:30.624691Z","iopub.status.idle":"2023-12-15T00:47:58.991058Z","shell.execute_reply.started":"2023-12-15T00:47:30.624661Z","shell.execute_reply":"2023-12-15T00:47:58.990000Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data['lemm_tokens'] = train_texts_from_bodies","metadata":{"execution":{"iopub.status.busy":"2023-12-15T00:47:58.992337Z","iopub.execute_input":"2023-12-15T00:47:58.992657Z","iopub.status.idle":"2023-12-15T00:47:59.005240Z","shell.execute_reply.started":"2023-12-15T00:47:58.992630Z","shell.execute_reply":"2023-12-15T00:47:59.004082Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data[train_data['group_id'] == 25]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T00:47:59.006756Z","iopub.execute_input":"2023-12-15T00:47:59.007791Z","iopub.status.idle":"2023-12-15T00:47:59.041967Z","shell.execute_reply.started":"2023-12-15T00:47:59.007742Z","shell.execute_reply":"2023-12-15T00:47:59.040766Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"      pair_id  group_id  doc_id  target  \\\n2115     2116        25   27577       1   \n2116     2117        25   26925       1   \n2117     2118        25   25096       1   \n2118     2119        25   25864       1   \n2119     2120        25   25859       1   \n...       ...       ...     ...     ...   \n2194     2195        25   27065       0   \n2195     2196        25   27962       0   \n2196     2197        25   27689       1   \n2197     2198        25   26139       1   \n2198     2199        25   26510       1   \n\n                                            lemm_tokens  \n2115  [адрес,  омск,  армия,  правило,  внутренний, ...  \n2116  [часто,  ходить,  солярий,  солярий,  это,  сп...  \n2117  [весь,  новый,  портал,  рецепт,  домашний,  у...  \n2118  [впервые,  часто,  посещать,  солярий,  навред...  \n2119  [весь,  право,  материал,  размещать,  сайт,  ...  \n...                                                 ...  \n2194  [солярий,  загар,  ноготь,  маникюр,  здравств...  \n2195  [солярий,  загар,  ноготь,  маникюр,  здравств...  \n2196  [салон,  красота,  спа,  прочее,  здоровье,  к...  \n2197  [совет,  загар,  солярий,  данный,  совет,  по...  \n2198  [интернет,  женщина,  сделать,  стартовый,  ст...  \n\n[84 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pair_id</th>\n      <th>group_id</th>\n      <th>doc_id</th>\n      <th>target</th>\n      <th>lemm_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2115</th>\n      <td>2116</td>\n      <td>25</td>\n      <td>27577</td>\n      <td>1</td>\n      <td>[адрес,  омск,  армия,  правило,  внутренний, ...</td>\n    </tr>\n    <tr>\n      <th>2116</th>\n      <td>2117</td>\n      <td>25</td>\n      <td>26925</td>\n      <td>1</td>\n      <td>[часто,  ходить,  солярий,  солярий,  это,  сп...</td>\n    </tr>\n    <tr>\n      <th>2117</th>\n      <td>2118</td>\n      <td>25</td>\n      <td>25096</td>\n      <td>1</td>\n      <td>[весь,  новый,  портал,  рецепт,  домашний,  у...</td>\n    </tr>\n    <tr>\n      <th>2118</th>\n      <td>2119</td>\n      <td>25</td>\n      <td>25864</td>\n      <td>1</td>\n      <td>[впервые,  часто,  посещать,  солярий,  навред...</td>\n    </tr>\n    <tr>\n      <th>2119</th>\n      <td>2120</td>\n      <td>25</td>\n      <td>25859</td>\n      <td>1</td>\n      <td>[весь,  право,  материал,  размещать,  сайт,  ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2194</th>\n      <td>2195</td>\n      <td>25</td>\n      <td>27065</td>\n      <td>0</td>\n      <td>[солярий,  загар,  ноготь,  маникюр,  здравств...</td>\n    </tr>\n    <tr>\n      <th>2195</th>\n      <td>2196</td>\n      <td>25</td>\n      <td>27962</td>\n      <td>0</td>\n      <td>[солярий,  загар,  ноготь,  маникюр,  здравств...</td>\n    </tr>\n    <tr>\n      <th>2196</th>\n      <td>2197</td>\n      <td>25</td>\n      <td>27689</td>\n      <td>1</td>\n      <td>[салон,  красота,  спа,  прочее,  здоровье,  к...</td>\n    </tr>\n    <tr>\n      <th>2197</th>\n      <td>2198</td>\n      <td>25</td>\n      <td>26139</td>\n      <td>1</td>\n      <td>[совет,  загар,  солярий,  данный,  совет,  по...</td>\n    </tr>\n    <tr>\n      <th>2198</th>\n      <td>2199</td>\n      <td>25</td>\n      <td>26510</td>\n      <td>1</td>\n      <td>[интернет,  женщина,  сделать,  стартовый,  ст...</td>\n    </tr>\n  </tbody>\n</table>\n<p>84 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_texts = []\nfor item in train_data['lemm_tokens']:\n    train_texts.append(''.join(item))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T00:47:59.043497Z","iopub.execute_input":"2023-12-15T00:47:59.043832Z","iopub.status.idle":"2023-12-15T00:48:02.713058Z","shell.execute_reply.started":"2023-12-15T00:47:59.043803Z","shell.execute_reply":"2023-12-15T00:48:02.711880Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer()\n\ndataset = vectorizer.fit_transform(train_texts)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T00:48:02.716172Z","iopub.execute_input":"2023-12-15T00:48:02.716566Z","iopub.status.idle":"2023-12-15T00:49:38.197662Z","shell.execute_reply.started":"2023-12-15T00:48:02.716533Z","shell.execute_reply":"2023-12-15T00:49:38.196573Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import LatentDirichletAllocation as LDA\n\nlda = LDA(n_components = 50,\n                 max_iter=20,\n                 n_jobs=6,\n                 learning_method='batch',\n                 verbose=1)\nlda.fit(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T01:13:41.635111Z","iopub.execute_input":"2023-12-15T01:13:41.635572Z","iopub.status.idle":"2023-12-15T01:37:55.407630Z","shell.execute_reply.started":"2023-12-15T01:13:41.635533Z","shell.execute_reply":"2023-12-15T01:37:55.406265Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"iteration: 1 of max_iter: 20\niteration: 2 of max_iter: 20\niteration: 3 of max_iter: 20\niteration: 4 of max_iter: 20\niteration: 5 of max_iter: 20\niteration: 6 of max_iter: 20\niteration: 7 of max_iter: 20\niteration: 8 of max_iter: 20\niteration: 9 of max_iter: 20\niteration: 10 of max_iter: 20\niteration: 11 of max_iter: 20\niteration: 12 of max_iter: 20\niteration: 13 of max_iter: 20\niteration: 14 of max_iter: 20\niteration: 15 of max_iter: 20\niteration: 16 of max_iter: 20\niteration: 17 of max_iter: 20\niteration: 18 of max_iter: 20\niteration: 19 of max_iter: 20\niteration: 20 of max_iter: 20\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"LatentDirichletAllocation(max_iter=20, n_components=50, n_jobs=6, verbose=1)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(max_iter=20, n_components=50, n_jobs=6, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(max_iter=20, n_components=50, n_jobs=6, verbose=1)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"class TopicModeler(object):\n    '''\n    Inteface object for CountVectorizer + LDA simple\n    usage.\n    '''\n    def __init__(self, count_vect, lda):\n        '''\n        Args:\n             count_vect - CountVectorizer object from sklearn.\n             lda - LDA object from sklearn.\n        '''\n        self.lda = lda\n        self.count_vect = count_vect\n        self.count_vect.input = 'content'\n\n    def __call__(self, text):\n        '''\n        Gives topics distribution for a given text\n        Args:\n             text - raw text via python string.\n        returns: numpy array - topics distribution for a given text.\n        '''\n        vectorized = self.count_vect.transform([text])\n        lda_topics = self.lda.transform(vectorized)\n        return lda_topics\n    def get_keywords(self, text, n_topics=3, n_keywords=5):\n        '''\n        For a given text gives n top keywords for each of m top texts topics.\n        Args:\n             text - raw text via python string.\n             n_topics - int how many top topics to use.\n             n_keywords - how many top words of each topic to return.\n        returns:\n                list - of m*n keywords for a given text.\n        '''\n        lda_topics = self(text)\n        lda_topics = np.squeeze(lda_topics, axis=0)\n        n_topics_indices = lda_topics.argsort()[-n_topics:][::-1]\n\n        top_topics_words_dists = []\n        for i in n_topics_indices:\n            top_topics_words_dists.append(self.lda.components_[i])\n\n        shape=(n_keywords*n_topics, self.lda.components_.shape[1])\n        keywords = np.zeros(shape=shape)\n        for i,topic in enumerate(top_topics_words_dists):\n            n_keywords_indices = topic.argsort()[-n_keywords:][::-1]\n            for k,j in enumerate(n_keywords_indices):\n                keywords[i * n_keywords + k, j] = 1\n        keywords = self.count_vect.inverse_transform(keywords)\n        keywords = [keyword[0] for keyword in keywords]\n        return keywords ","metadata":{"execution":{"iopub.status.busy":"2023-12-15T01:37:57.873201Z","iopub.execute_input":"2023-12-15T01:37:57.873528Z","iopub.status.idle":"2023-12-15T01:37:57.886950Z","shell.execute_reply.started":"2023-12-15T01:37:57.873500Z","shell.execute_reply":"2023-12-15T01:37:57.885720Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-12-15T01:13:33.176137Z","iopub.status.idle":"2023-12-15T01:13:33.176926Z","shell.execute_reply.started":"2023-12-15T01:13:33.176697Z","shell.execute_reply":"2023-12-15T01:13:33.176720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train_data[train_data['group_id'] < 50].drop(columns=['target'])\ny_train = train_data[train_data['group_id'] < 50]['target']\n\nX_val = train_data[train_data['group_id'] > 101].drop(columns=['target'])\ny_val = train_data[train_data['group_id'] > 101]['target']","metadata":{"execution":{"iopub.status.busy":"2023-12-15T01:50:05.929024Z","iopub.execute_input":"2023-12-15T01:50:05.930119Z","iopub.status.idle":"2023-12-15T01:50:05.950780Z","shell.execute_reply.started":"2023-12-15T01:50:05.930081Z","shell.execute_reply":"2023-12-15T01:50:05.949275Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"modeler = TopicModeler(vectorizer, lda)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T01:37:57.888940Z","iopub.execute_input":"2023-12-15T01:37:57.889416Z","iopub.status.idle":"2023-12-15T01:37:57.903022Z","shell.execute_reply.started":"2023-12-15T01:37:57.889372Z","shell.execute_reply":"2023-12-15T01:37:57.901728Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_texts = []\nfor item in tqdm(X_train['lemm_tokens']):\n    train_texts.append(modeler(''.join(item)))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T01:50:10.050384Z","iopub.execute_input":"2023-12-15T01:50:10.050808Z","iopub.status.idle":"2023-12-15T02:10:26.673146Z","shell.execute_reply.started":"2023-12-15T01:50:10.050775Z","shell.execute_reply":"2023-12-15T02:10:26.670766Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"100%|██████████| 4402/4402 [20:16<00:00,  3.62it/s]\n  0%|          | 0/2589 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m val_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tqdm(X_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemm_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtest_texts\u001b[49m\u001b[38;5;241m.\u001b[39mappend(modeler(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(item)))\n","\u001b[0;31mNameError\u001b[0m: name 'test_texts' is not defined"],"ename":"NameError","evalue":"name 'test_texts' is not defined","output_type":"error"}]},{"cell_type":"code","source":"val_texts = []\nfor item in tqdm(X_val['lemm_tokens']):\n    val_texts.append(modeler(''.join(item)))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:10:51.554026Z","iopub.execute_input":"2023-12-15T02:10:51.555378Z","iopub.status.idle":"2023-12-15T02:22:41.253245Z","shell.execute_reply.started":"2023-12-15T02:10:51.555324Z","shell.execute_reply":"2023-12-15T02:22:41.252279Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"100%|██████████| 2589/2589 [11:49<00:00,  3.65it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(len(train_texts)):\n    train_texts[i] = train_texts[i][0]\n\nfor i in range(len(val_texts)):\n    val_texts[i] = val_texts[i][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:25:17.372830Z","iopub.execute_input":"2023-12-15T02:25:17.373342Z","iopub.status.idle":"2023-12-15T02:25:17.389751Z","shell.execute_reply.started":"2023-12-15T02:25:17.373305Z","shell.execute_reply":"2023-12-15T02:25:17.388655Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:22:41.255882Z","iopub.execute_input":"2023-12-15T02:22:41.256962Z","iopub.status.idle":"2023-12-15T02:22:41.263335Z","shell.execute_reply.started":"2023-12-15T02:22:41.256914Z","shell.execute_reply":"2023-12-15T02:22:41.262071Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nclf = SVC(verbose=True)\n\nclf.fit(train_texts, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:26:35.969983Z","iopub.execute_input":"2023-12-15T02:26:35.970454Z","iopub.status.idle":"2023-12-15T02:26:36.623338Z","shell.execute_reply.started":"2023-12-15T02:26:35.970417Z","shell.execute_reply":"2023-12-15T02:26:36.622288Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"[LibSVM]..**.*\noptimization finished, #iter = 2809\nobj = -1829.880464, rho = -0.590524\nnSV = 2089, nBSV = 1836\nTotal nSV = 2089\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"SVC(verbose=True)","text/html":"<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(verbose=True)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"preds = clf.predict(val_texts)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:26:38.905722Z","iopub.execute_input":"2023-12-15T02:26:38.906434Z","iopub.status.idle":"2023-12-15T02:26:39.334613Z","shell.execute_reply.started":"2023-12-15T02:26:38.906395Z","shell.execute_reply":"2023-12-15T02:26:39.333636Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nf1_score(y_val, preds)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:26:40.911239Z","iopub.execute_input":"2023-12-15T02:26:40.911646Z","iopub.status.idle":"2023-12-15T02:26:40.923092Z","shell.execute_reply.started":"2023-12-15T02:26:40.911615Z","shell.execute_reply":"2023-12-15T02:26:40.922102Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"0.23357664233576642"},"metadata":{}}]},{"cell_type":"code","source":"y_val","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:26:50.246331Z","iopub.execute_input":"2023-12-15T02:26:50.246775Z","iopub.status.idle":"2023-12-15T02:26:50.256683Z","shell.execute_reply.started":"2023-12-15T02:26:50.246739Z","shell.execute_reply":"2023-12-15T02:26:50.255300Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"9101     1\n9102     0\n9103     0\n9104     0\n9105     0\n        ..\n11685    0\n11686    0\n11687    0\n11688    0\n11689    0\nName: target, Length: 2589, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"np.unique(preds, return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T02:27:35.237164Z","iopub.execute_input":"2023-12-15T02:27:35.237571Z","iopub.status.idle":"2023-12-15T02:27:35.245725Z","shell.execute_reply.started":"2023-12-15T02:27:35.237540Z","shell.execute_reply":"2023-12-15T02:27:35.244688Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(array([0, 1]), array([2444,  145]))"},"metadata":{}}]}]}