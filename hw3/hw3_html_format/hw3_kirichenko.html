<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>f568ff39dc14466da050e418af098715</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" id="-e0JoY0KayY8">
<h3 id="машинное-обучение">Машинное обучение</h3>
<h2 id="домашнее-задание-3---градиентный-бустинг">Домашнее задание №3 -
Градиентный бустинг</h2>
</div>
<div class="cell markdown" id="TOiEV-3wayY-">
<p><strong>Общая информация</strong></p>
<p><strong>Срок сдачи:</strong> 5 декабря 2023, 23:59<br />
<strong>Штраф за опоздание:</strong> -2 балла за каждые сутки</p>
<p>Используйте данный Ipython Notebook при оформлении домашнего
задания.</p>
</div>
<section id="считаем-производные-для-функций-потерь-1-балл"
class="cell markdown" id="cbBLiJf-ayY_">
<h2>Считаем производные для функций потерь (1 балл)</h2>
</section>
<div class="cell markdown" id="V4HLlFkXayY_">
<p>Мы будем реализовать градиентный бустинг для 3 функций потерь:</p>
<p>1) MSE <span
class="math inline"><em>L</em>(<em>a</em>(<em>x</em><sub><em>i</em></sub>),<em>y</em><sub><em>i</em></sub>) = (<em>y</em><sub><em>i</em></sub>−<em>a</em>(<em>x</em><sub><em>i</em></sub>))<sup>2</sup></span></p>
<p>2) Экспоненциальная <span
class="math inline"><em>L</em>(<em>a</em>(<em>x</em><sub><em>i</em></sub>),<em>y</em><sub><em>i</em></sub>) = <em>e</em><em>x</em><em>p</em>(−<em>a</em>(<em>x</em><sub><em>i</em></sub>)<em>y</em><sub><em>i</em></sub>), <em>y</em><sub><em>i</em></sub> ∈ { − 1, 1}</span></p>
<p>3) Логистическая <span
class="math inline"><em>L</em>(<em>a</em>(<em>x</em><sub><em>i</em></sub>),<em>y</em><sub><em>i</em></sub>) = log (1+<em>e</em><em>x</em><em>p</em>(−<em>a</em>(<em>x</em><sub><em>i</em></sub>)<em>y</em><sub><em>i</em></sub>)), <em>y</em><sub><em>i</em></sub> ∈ { − 1, 1}</span></p>
<p>где <span
class="math inline"><em>a</em>(<em>x</em><sub><em>i</em></sub>)</span>
предсказание бустинга на итом объекте.</p>
<p>Для каждой функции потерь напишите таргет, на который будет
настраиваться каждое дерево в бустинге.</p>
</div>
<div class="cell markdown" id="m9DZ69eCayY_">
<p>Ваше решение тут</p>
</div>
<div class="cell code" data-execution_count="22" id="Dlktm5ggdX6U">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse_loss(targets, predictions):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean((targets <span class="op">-</span> predictions) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse_loss_gradients(targets, predictions):</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="dv">2</span> <span class="op">*</span> targets <span class="op">*</span> (targets <span class="op">-</span> predictions)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> exp_loss(targets, predictions):</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(<span class="op">-</span>targets <span class="op">/</span> np.exp(targets <span class="op">*</span> predictions))</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> exp_loss_gradients(targets, predictions):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>targets <span class="op">/</span> np.exp(targets <span class="op">*</span> predictions)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_loss(targets, predictions):</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(np.log(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>targets <span class="op">*</span> predictions)))</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_loss_gradients(targets, predictions):</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>targets <span class="op">/</span> np.exp(targets <span class="op">*</span> predictions <span class="op">+</span> <span class="dv">1</span>)</span></code></pre></div>
</div>
<section id="реализуем-градиентный-бустинг-3-балла"
class="cell markdown" id="-6vTaNgNayY_">
<h2>Реализуем градиентный бустинг (3 балла)</h2>
</section>
<div class="cell markdown" id="MqvWwBgmayZA">
<p>Реализуйте класс градиентного бустинга для классификации. Ваша
реализация бустинга должна работать по точности не более чем на 5
процентов хуже чем GradientBoostingClassifier из sklearn.</p>
</div>
<div class="cell markdown" id="iXoi7XkwayZA">
<p>Детали реализации:</p>
<p>-- должно поддерживаться 3 функции потерь</p>
<p>-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать
не надо, просто возьмите готовые из sklearn</p>
<p>-- в качестве функции потерь для построения одного дерева используйте
MSE</p>
<p>-- шаг в бустинге можно не подбирать, можно брать константный</p>
<p>-- можно брать разные модели в качестве инициализации бустинга</p>
<p>-- должны поддерживаться следующие параметры:</p>
<p>а) число итераций б) размер шага в) процент случайных фичей при
построении одного дерева д) процент случайных объектов при построении
одного дерева е) параметры базового алгоритма (передавайте через
**kwargs)</p>
</div>
<div class="cell code" data-execution_count="6" data-collapsed="true"
id="vOZKHFElayZA" data-jupyter="{&quot;outputs_hidden&quot;:true}">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_wine</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingClassifier</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="20" data-collapsed="true"
id="LPullC73ayZA" data-jupyter="{&quot;outputs_hidden&quot;:true}">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># class MyGradientBoostingClassifier:</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#     def __init__(self, loss, learning_rate, n_estimators, colsample, subsample, *args, **kwargs):</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">#         &quot;&quot;&quot;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#         loss -- один из 3 лоссов:</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">#         learning_rate -- шаг бустинга</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">#         n_estimators -- число итераций</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">#         colsample -- процент рандомных признаков при обучнеии одного алгоритма</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">#         colsample -- процент рандомных объектов при обучнеии одного алгоритма</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">#         args, kwargs -- параметры  базовых моделей</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">#         &quot;&quot;&quot;</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">#         # Ваш код здесь</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">#         if loss == &#39;MSE&#39;:</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co">#             self.loss = mse_loss</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">#             self.grad = mse_loss_gradients</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co">#         elif loss == &#39;Exponential&#39;:</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co">#             self.loss = exp_loss</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co">#             self.grad = exp_loss_gradients</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co">#         elif loss == &#39;LogLoss&#39;:</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co">#             self.loss = log_loss</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co">#             self.grad = log_loss_gradients</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co">#         self.lr = learning_rate</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co">#         self.n_estimators = n_estimators</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co">#         self.colsample = colsample</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co">#         self.subsample = subsample</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="co">#         self.base_algo_params = kwargs</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co">#     def fit(self, X, y, base_model, init_model=None):</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co">#         &quot;&quot;&quot;</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co">#         X -- объекты для обучения:</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co">#         y -- таргеты для обучения</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="co">#         base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="co">#         init_model -- класс для первой модели, если None то берем константу (только для посл задания)</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="co">#         &quot;&quot;&quot;</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="co">#         # Ваш код здесь</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a><span class="co">#         if init_model is None:</span></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="co">#             self.class_count = len(np.unique(y))</span></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a><span class="co">#             new_y = np.zeros((len(y), self.class_count))</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="co">#             for i in range(len(y)):</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a><span class="co">#                 new_y[i][y[i]] = 1</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a><span class="co">#         else:</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a><span class="co">#             init_model = init_model()</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a><span class="co">#             init_model.fit(X, y)</span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a><span class="co">#             new_y = init_model.predict(X)</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a><span class="co">#         self.models_list = []</span></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a><span class="co">#         self.losses = []</span></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a><span class="co">#         for step in range(self.n_estimators):</span></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="co">#             models_layer = []</span></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a><span class="co">#             for class_num in range(self.class_count):</span></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a><span class="co">#                 model = base_model()</span></span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a><span class="co">#                 models_layer.append(model.fit(X, new_y[:, class_num]))</span></span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a><span class="co">#             self.models_list.append(models_layer)</span></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a><span class="co">#             self.predict(X)</span></span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a><span class="co">#             self.losses.append(self.loss(new_y, self.pred_fit))</span></span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a><span class="co">#             gradients = self.grad(new_y, self.pred_fit)</span></span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a><span class="co">#             new_y = - gradients</span></span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a><span class="co">#         return self</span></span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a><span class="co">#     def predict(self, X):</span></span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a><span class="co">#         predictions = np.zeros((len(X), self.class_count))</span></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a><span class="co">#         for layer in range(len(self.models_list)):</span></span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a><span class="co">#             for model_num in range(self.class_count):</span></span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a><span class="co">#                 predictions[:, model_num] += self.models_list[layer][model_num].predict(X) * self.lr</span></span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a><span class="co">#         self.pred_fit = predictions</span></span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a><span class="co">#         predictions = np.argmax(predictions, axis=1)</span></span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a><span class="co">#         return predictions</span></span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ModelsAnsemble:</span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models_list <span class="op">=</span> []</span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_models_layer(<span class="va">self</span>, fitted_layer):</span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-90"><a href="#cb3-90" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models_list.append(fitted_layer)</span>
<span id="cb3-91"><a href="#cb3-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-92"><a href="#cb3-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-93"><a href="#cb3-93" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyGradientBoostingClassifier:</span>
<span id="cb3-94"><a href="#cb3-94" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, loss, learning_rate, n_estimators, subsample<span class="op">=</span><span class="va">None</span>, colsample<span class="op">=</span><span class="fl">1.0</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb3-95"><a href="#cb3-95" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb3-96"><a href="#cb3-96" aria-hidden="true" tabindex="-1"></a><span class="co">        loss -- один из 3 лоссов:</span></span>
<span id="cb3-97"><a href="#cb3-97" aria-hidden="true" tabindex="-1"></a><span class="co">        learning_rate -- шаг бустинга</span></span>
<span id="cb3-98"><a href="#cb3-98" aria-hidden="true" tabindex="-1"></a><span class="co">        n_estimators -- число итераций</span></span>
<span id="cb3-99"><a href="#cb3-99" aria-hidden="true" tabindex="-1"></a><span class="co">        colsample -- процент рандомных признаков при обучнеии одного алгоритма</span></span>
<span id="cb3-100"><a href="#cb3-100" aria-hidden="true" tabindex="-1"></a><span class="co">        colsample -- процент рандомных объектов при обучнеии одного алгоритма</span></span>
<span id="cb3-101"><a href="#cb3-101" aria-hidden="true" tabindex="-1"></a><span class="co">        args, kwargs -- параметры  базовых моделей</span></span>
<span id="cb3-102"><a href="#cb3-102" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb3-103"><a href="#cb3-103" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ваш код здесь</span></span>
<span id="cb3-104"><a href="#cb3-104" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> loss <span class="op">==</span> <span class="st">&#39;MSE&#39;</span>:</span>
<span id="cb3-105"><a href="#cb3-105" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.loss <span class="op">=</span> mse_loss</span>
<span id="cb3-106"><a href="#cb3-106" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grad <span class="op">=</span> mse_loss_gradients</span>
<span id="cb3-107"><a href="#cb3-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-108"><a href="#cb3-108" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> loss <span class="op">==</span> <span class="st">&#39;Exponential&#39;</span>:</span>
<span id="cb3-109"><a href="#cb3-109" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.loss <span class="op">=</span> exp_loss</span>
<span id="cb3-110"><a href="#cb3-110" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grad <span class="op">=</span> exp_loss_gradients</span>
<span id="cb3-111"><a href="#cb3-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-112"><a href="#cb3-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> loss <span class="op">==</span> <span class="st">&#39;LogLoss&#39;</span>:</span>
<span id="cb3-113"><a href="#cb3-113" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.loss <span class="op">=</span> log_loss</span>
<span id="cb3-114"><a href="#cb3-114" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grad <span class="op">=</span> log_loss_gradients</span>
<span id="cb3-115"><a href="#cb3-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-116"><a href="#cb3-116" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> learning_rate</span>
<span id="cb3-117"><a href="#cb3-117" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_estimators <span class="op">=</span> n_estimators</span>
<span id="cb3-118"><a href="#cb3-118" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.colsample <span class="op">=</span> colsample</span>
<span id="cb3-119"><a href="#cb3-119" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.subsample <span class="op">=</span> subsample</span>
<span id="cb3-120"><a href="#cb3-120" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.args <span class="op">=</span> args</span>
<span id="cb3-121"><a href="#cb3-121" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.base_algo_params <span class="op">=</span> kwargs</span>
<span id="cb3-122"><a href="#cb3-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-123"><a href="#cb3-123" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y, base_model, init_model<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb3-124"><a href="#cb3-124" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb3-125"><a href="#cb3-125" aria-hidden="true" tabindex="-1"></a><span class="co">        X -- объекты для обучения:</span></span>
<span id="cb3-126"><a href="#cb3-126" aria-hidden="true" tabindex="-1"></a><span class="co">        y -- таргеты для обучения</span></span>
<span id="cb3-127"><a href="#cb3-127" aria-hidden="true" tabindex="-1"></a><span class="co">        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor</span></span>
<span id="cb3-128"><a href="#cb3-128" aria-hidden="true" tabindex="-1"></a><span class="co">        init_model -- класс для первой модели, если None то берем константу (только для посл задания)</span></span>
<span id="cb3-129"><a href="#cb3-129" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb3-130"><a href="#cb3-130" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ваш код здесь</span></span>
<span id="cb3-131"><a href="#cb3-131" aria-hidden="true" tabindex="-1"></a>        <span class="co"># X = np.array(X)</span></span>
<span id="cb3-132"><a href="#cb3-132" aria-hidden="true" tabindex="-1"></a>        rows_count, cols_count <span class="op">=</span> X.shape</span>
<span id="cb3-133"><a href="#cb3-133" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.class_names, class_counts <span class="op">=</span> np.unique(y, return_counts<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-134"><a href="#cb3-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-135"><a href="#cb3-135" aria-hidden="true" tabindex="-1"></a>        y_ohe <span class="op">=</span> np.zeros((<span class="bu">len</span>(y), <span class="bu">len</span>(<span class="va">self</span>.class_names)))</span>
<span id="cb3-136"><a href="#cb3-136" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(y)):</span>
<span id="cb3-137"><a href="#cb3-137" aria-hidden="true" tabindex="-1"></a>            y_ohe[i][y[i]] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb3-138"><a href="#cb3-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-139"><a href="#cb3-139" aria-hidden="true" tabindex="-1"></a>        y_prob <span class="op">=</span> class_counts <span class="op">/</span> np.<span class="bu">sum</span>(class_counts)</span>
<span id="cb3-140"><a href="#cb3-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-141"><a href="#cb3-141" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> init_model <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb3-142"><a href="#cb3-142" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.start_y <span class="op">=</span> []</span>
<span id="cb3-143"><a href="#cb3-143" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(y)):</span>
<span id="cb3-144"><a href="#cb3-144" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.start_y.append(y_prob)</span>
<span id="cb3-145"><a href="#cb3-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-146"><a href="#cb3-146" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb3-147"><a href="#cb3-147" aria-hidden="true" tabindex="-1"></a>            init_model <span class="op">=</span> init_model()</span>
<span id="cb3-148"><a href="#cb3-148" aria-hidden="true" tabindex="-1"></a>            init_model.fit(X, y)</span>
<span id="cb3-149"><a href="#cb3-149" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.start_y <span class="op">=</span> init_model.predict_proba(X)</span>
<span id="cb3-150"><a href="#cb3-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-151"><a href="#cb3-151" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.subsample:</span>
<span id="cb3-152"><a href="#cb3-152" aria-hidden="true" tabindex="-1"></a>            n_subsamples <span class="op">=</span> <span class="bu">int</span>(<span class="va">self</span>.subsample <span class="op">*</span> rows_count)</span>
<span id="cb3-153"><a href="#cb3-153" aria-hidden="true" tabindex="-1"></a>        n_colsamples <span class="op">=</span> <span class="bu">int</span>(<span class="va">self</span>.colsample <span class="op">*</span> cols_count)</span>
<span id="cb3-154"><a href="#cb3-154" aria-hidden="true" tabindex="-1"></a>        new_y <span class="op">=</span> <span class="va">self</span>.start_y</span>
<span id="cb3-155"><a href="#cb3-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-156"><a href="#cb3-156" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models_ansemble <span class="op">=</span> ModelsAnsemble()</span>
<span id="cb3-157"><a href="#cb3-157" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_estimators):</span>
<span id="cb3-158"><a href="#cb3-158" aria-hidden="true" tabindex="-1"></a>            gradient <span class="op">=</span> <span class="op">-</span><span class="va">self</span>.grad(y_ohe, new_y)</span>
<span id="cb3-159"><a href="#cb3-159" aria-hidden="true" tabindex="-1"></a>            models_list <span class="op">=</span> []</span>
<span id="cb3-160"><a href="#cb3-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-161"><a href="#cb3-161" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.subsample:</span>
<span id="cb3-162"><a href="#cb3-162" aria-hidden="true" tabindex="-1"></a>                subsamples <span class="op">=</span> np.random.choice(np.arange(rows_count), size<span class="op">=</span>n_subsamples, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-163"><a href="#cb3-163" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb3-164"><a href="#cb3-164" aria-hidden="true" tabindex="-1"></a>                subsamples <span class="op">=</span> np.arange(X.shape[<span class="dv">0</span>])</span>
<span id="cb3-165"><a href="#cb3-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-166"><a href="#cb3-166" aria-hidden="true" tabindex="-1"></a>            colsamples <span class="op">=</span> np.random.choice(cols_count, size<span class="op">=</span>n_colsamples, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-167"><a href="#cb3-167" aria-hidden="true" tabindex="-1"></a>            X_samp <span class="op">=</span> X[subsamples, :][:, colsamples]</span>
<span id="cb3-168"><a href="#cb3-168" aria-hidden="true" tabindex="-1"></a>            y_samp <span class="op">=</span> gradient[subsamples, :]</span>
<span id="cb3-169"><a href="#cb3-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-170"><a href="#cb3-170" aria-hidden="true" tabindex="-1"></a>            test_pred <span class="op">=</span> []</span>
<span id="cb3-171"><a href="#cb3-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-172"><a href="#cb3-172" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(<span class="va">self</span>.class_names)):</span>
<span id="cb3-173"><a href="#cb3-173" aria-hidden="true" tabindex="-1"></a>                estimator <span class="op">=</span> base_model(<span class="op">*</span><span class="va">self</span>.args, <span class="op">**</span><span class="va">self</span>.base_algo_params)</span>
<span id="cb3-174"><a href="#cb3-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-175"><a href="#cb3-175" aria-hidden="true" tabindex="-1"></a>                estimator.fit(X_samp, y_samp[:, i])</span>
<span id="cb3-176"><a href="#cb3-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-177"><a href="#cb3-177" aria-hidden="true" tabindex="-1"></a>                models_list.append(estimator)</span>
<span id="cb3-178"><a href="#cb3-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-179"><a href="#cb3-179" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.models_ansemble.add_models_layer((models_list, colsamples))</span>
<span id="cb3-180"><a href="#cb3-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-181"><a href="#cb3-181" aria-hidden="true" tabindex="-1"></a>            new_y <span class="op">+=</span> <span class="va">self</span>.lr <span class="op">*</span> <span class="va">self</span>.layer_predict((models_list, colsamples), X_samp)</span>
<span id="cb3-182"><a href="#cb3-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-183"><a href="#cb3-183" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> layer_predict(<span class="va">self</span>, models_list, X):</span>
<span id="cb3-184"><a href="#cb3-184" aria-hidden="true" tabindex="-1"></a>        models_list, colsamples <span class="op">=</span> models_list[<span class="dv">0</span>], models_list[<span class="dv">1</span>]</span>
<span id="cb3-185"><a href="#cb3-185" aria-hidden="true" tabindex="-1"></a>        X_samp <span class="op">=</span> X[:, colsamples]</span>
<span id="cb3-186"><a href="#cb3-186" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> np.zeros((<span class="bu">len</span>(X_samp), <span class="bu">len</span>(models_list)))</span>
<span id="cb3-187"><a href="#cb3-187" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(models_list)):</span>
<span id="cb3-188"><a href="#cb3-188" aria-hidden="true" tabindex="-1"></a>            preds[:, i] <span class="op">=</span> models_list[i].predict(X_samp)</span>
<span id="cb3-189"><a href="#cb3-189" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> preds</span>
<span id="cb3-190"><a href="#cb3-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-191"><a href="#cb3-191" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb3-192"><a href="#cb3-192" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> np.zeros((<span class="bu">len</span>(X), <span class="bu">len</span>(<span class="va">self</span>.class_names)))</span>
<span id="cb3-193"><a href="#cb3-193" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">+=</span> np.array(<span class="va">self</span>.start_y[:<span class="bu">len</span>(X)]) <span class="op">*</span> <span class="va">self</span>.lr</span>
<span id="cb3-194"><a href="#cb3-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-195"><a href="#cb3-195" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> model_layer <span class="kw">in</span> <span class="va">self</span>.models_ansemble.models_list:</span>
<span id="cb3-196"><a href="#cb3-196" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">+=</span> <span class="va">self</span>.layer_predict(model_layer, X) <span class="op">*</span> <span class="va">self</span>.lr</span>
<span id="cb3-197"><a href="#cb3-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-198"><a href="#cb3-198" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(pred)</span></span>
<span id="cb3-199"><a href="#cb3-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-200"><a href="#cb3-200" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.argmax(pred, axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="702" id="DR_-ijHuayZB">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>my_clf <span class="op">=</span> MyGradientBoostingClassifier(<span class="st">&#39;LogLoss&#39;</span>, <span class="fl">0.1</span>, <span class="dv">5</span>, max_depth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> GradientBoostingClassifier()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="627" data-collapsed="true"
id="C9oMApR4ayZB" data-jupyter="{&quot;outputs_hidden&quot;:true}">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>wine <span class="op">=</span> load_wine()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(wine.data, wine.target, test_size<span class="op">=</span><span class="fl">0.1</span>, stratify<span class="op">=</span>wine.target)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="703" id="IPMLVcmO_t2g">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>my_clf.fit(X_train, y_train, DecisionTreeRegressor)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> my_clf.predict(X_test)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="706"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="7nBkhWd1Gax-" data-outputId="d5c0a26c-1ec4-4111-a641-c89fa8f7b611">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>pred</span></code></pre></div>
<div class="output execute_result" data-execution_count="706">
<pre><code>array([0, 2, 0, 2, 0, 2, 1, 0, 0, 0, 2, 0, 1, 1, 1, 1, 1, 1])</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="707"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="rL24UXGuN15L" data-outputId="4660bf05-e57e-4379-dfc2-06cd92ac4e4a">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>y_test</span></code></pre></div>
<div class="output execute_result" data-execution_count="707">
<pre><code>array([0, 2, 1, 2, 0, 2, 1, 0, 0, 0, 2, 0, 1, 1, 1, 2, 1, 1])</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="708"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="dkE1-5cdayZB" data-outputId="442cb003-d492-4c72-ab73-a1485549dae2">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>my_clf.fit(X_train, y_train, DecisionTreeRegressor)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(accuracy_score(y_pred<span class="op">=</span>clf.predict(X_test), y_true<span class="op">=</span>y_test))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(accuracy_score(y_pred<span class="op">=</span>my_clf.predict(X_test), y_true<span class="op">=</span>y_test))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>0.8888888888888888
0.8888888888888888
</code></pre>
</div>
</div>
<section id="подбираем-параметры-2-балла" class="cell markdown"
id="CbCwunTXayZB">
<h2>Подбираем параметры (2 балла)</h2>
<p>Давайте попробуем применить Ваш бустинг для предсказаний цены домов в
Калифорнии. Чтобы можно было попробовтаь разные функции потерь,
переведем по порогу таргет в 2 класса: дорогие и дешевые дома.</p>
</section>
<div class="cell markdown" id="IPzEf-vFayZB">
<p>В задании нужно</p>
<p>1) Построить график точности в зависимости от числа итераций на
валидации.</p>
<p>2) Подобрать оптимальные параметры Вашего бустинга на валидации.</p>
</div>
<div class="cell code" data-execution_count="8" id="JaqhFQFuayZB">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> fetch_california_housing(return_X_y<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="9"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ih8geN9fayZB" data-outputId="b44f621b-8806-4625-fe6f-1e0855fd4880">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Превращаем регрессию в классификацию</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (y <span class="op">&gt;</span> <span class="fl">2.0</span>).astype(<span class="bu">int</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.shape, y.shape)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>(20640, 8) (20640,)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="10" data-collapsed="true"
id="2PIpu_KaayZB" data-jupyter="{&quot;outputs_hidden&quot;:true}">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="727"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:49,&quot;referenced_widgets&quot;:[&quot;b0b5486c81214007a204553791918f7e&quot;,&quot;1fe506bbebbd470da41b170eb4308217&quot;,&quot;86a1f36b5e5a40ca931a5f66261ad282&quot;,&quot;6d4db1d4263a496291413eefe099c52d&quot;,&quot;894ac139c3df4cb680990cfee5253fa7&quot;,&quot;f2f213080e794ec2b59ad24737497578&quot;,&quot;260ac9fccd36418780a6230b03cd8665&quot;,&quot;b7c6e293f2a9475f9f3015fd3c6f6853&quot;,&quot;bb9cba9e736c40c58c4f47a087af1fee&quot;,&quot;2cd344189a5d4839b49c2bbb387e9319&quot;,&quot;9761ec5b690a4214a7cb80b56e355e07&quot;]}"
id="aQW1HVy9Yi7z" data-outputId="eecfa8e7-2641-490f-944c-57af3e1d5695">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> [<span class="st">&#39;Exponential&#39;</span>, <span class="st">&#39;MSE&#39;</span>, <span class="st">&#39;LogLoss&#39;</span>]</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>exp_acc <span class="op">=</span> {<span class="st">&#39;test&#39;</span>: [],</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>           <span class="st">&#39;train&#39;</span>: []}</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>log_acc <span class="op">=</span> {<span class="st">&#39;test&#39;</span>: [],</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>           <span class="st">&#39;train&#39;</span>: []}</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>mse_acc <span class="op">=</span> {<span class="st">&#39;test&#39;</span>: [],</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>           <span class="st">&#39;train&#39;</span>: []}</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> iteration <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">200</span>, <span class="dv">10</span>)):</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    my_clf <span class="op">=</span> MyGradientBoostingClassifier(<span class="st">&#39;MSE&#39;</span>, <span class="fl">0.2</span>, iteration, <span class="dv">1</span>, <span class="dv">1</span>, max_depth<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    my_clf.fit(X_train, y_train, DecisionTreeRegressor)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    mse_acc[<span class="st">&#39;test&#39;</span>].append(accuracy_score(y_pred<span class="op">=</span>my_clf.predict(X_test), y_true<span class="op">=</span>y_test))</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    mse_acc[<span class="st">&#39;train&#39;</span>].append(accuracy_score(y_pred<span class="op">=</span>my_clf.predict(X_train), y_true<span class="op">=</span>y_train))</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    my_clf <span class="op">=</span> MyGradientBoostingClassifier(<span class="st">&#39;Exponential&#39;</span>, <span class="fl">0.2</span>, iteration, <span class="dv">1</span>, <span class="dv">1</span>, max_depth<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    my_clf.fit(X_train, y_train, DecisionTreeRegressor)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    exp_acc[<span class="st">&#39;test&#39;</span>].append(accuracy_score(y_pred<span class="op">=</span>my_clf.predict(X_test), y_true<span class="op">=</span>y_test))</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    exp_acc[<span class="st">&#39;train&#39;</span>].append(accuracy_score(y_pred<span class="op">=</span>my_clf.predict(X_train), y_true<span class="op">=</span>y_train))</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    my_clf <span class="op">=</span> MyGradientBoostingClassifier(<span class="st">&#39;LogLoss&#39;</span>, <span class="fl">0.2</span>, iteration, <span class="dv">1</span>, <span class="dv">1</span>, max_depth<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    my_clf.fit(X_train, y_train, DecisionTreeRegressor)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    log_acc[<span class="st">&#39;test&#39;</span>].append(accuracy_score(y_pred<span class="op">=</span>my_clf.predict(X_test), y_true<span class="op">=</span>y_test))</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    log_acc[<span class="st">&#39;train&#39;</span>].append(accuracy_score(y_pred<span class="op">=</span>my_clf.predict(X_train), y_true<span class="op">=</span>y_train))</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb18"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b0b5486c81214007a204553791918f7e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div class="cell code" data-execution_count="728"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:504}"
id="-SjD-lMzfugf" data-outputId="8e1eb576-4e7d-4d8b-8011-56c8dd993cfb">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> [i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">200</span>, <span class="dv">10</span>)]</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mse_acc[<span class="st">&#39;test&#39;</span>])</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>plt.plot(x, mse_acc[<span class="st">&#39;test&#39;</span>], x, mse_acc[<span class="st">&#39;train&#39;</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[0.8275193798449613, 0.8551356589147286, 0.8556201550387597, 0.8083817829457365, 0.7790697674418605, 0.657218992248062, 0.6836240310077519, 0.7078488372093024, 0.84375, 0.8524709302325582, 0.8502906976744186, 0.751453488372093, 0.7538759689922481, 0.8267926356589147, 0.8074127906976745, 0.6322674418604651, 0.39292635658914726, 0.8500484496124031, 0.5729166666666666, 0.280765503875969]
</code></pre>
</div>
<div class="output execute_result" data-execution_count="728">
<pre><code>[&lt;matplotlib.lines.Line2D at 0x784451fcf790&gt;,
 &lt;matplotlib.lines.Line2D at 0x784451fcf7f0&gt;]</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b0b7f9a659714f46b06eb9a7b83e330b/fdc6f9857489ea26b8770225acc0e0a0a3f290a9.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="729"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:466}"
id="kgIwI7v5TAXY" data-outputId="1bbf4be5-d1d9-4be1-f000-c8ded80c3b83">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x, log_acc[<span class="st">&#39;test&#39;</span>], x, log_acc[<span class="st">&#39;train&#39;</span>])</span></code></pre></div>
<div class="output execute_result" data-execution_count="729">
<pre><code>[&lt;matplotlib.lines.Line2D at 0x784451e7a7a0&gt;,
 &lt;matplotlib.lines.Line2D at 0x784451e7a800&gt;]</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b0b7f9a659714f46b06eb9a7b83e330b/7602a3e59619d19afe265727301b0328912cad4e.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="730"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:466}"
id="s3gYTNtDTB8s" data-outputId="cf066852-081c-4640-9a48-3b33e410b9c8">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x, exp_acc[<span class="st">&#39;test&#39;</span>], x, exp_acc[<span class="st">&#39;train&#39;</span>])</span></code></pre></div>
<div class="output execute_result" data-execution_count="730">
<pre><code>[&lt;matplotlib.lines.Line2D at 0x784451efef80&gt;,
 &lt;matplotlib.lines.Line2D at 0x784451efefe0&gt;]</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_b0b7f9a659714f46b06eb9a7b83e330b/e3a47ef9d2c4eff0fd8d7f6f1e4b9d4c0d36ca8e.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="738"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="LSXuwsvlYaK7" data-outputId="cfb25fa5-a3b1-4237-d728-063a682dc026">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="bu">max</span>(log_acc[<span class="st">&#39;test&#39;</span>])</span></code></pre></div>
<div class="output execute_result" data-execution_count="738">
<pre><code>0.8594961240310077</code></pre>
</div>
</div>
<div class="cell markdown" id="42xW6qScXuE1">
<p>Оптимально использовать Логистическую функцию потерь и 55
итераций</p>
</div>
<section id="boobag-bagboo-1-балл" class="cell markdown"
id="1w87o0lDayZB">
<h2>BooBag BagBoo (1 балл)</h2>
</section>
<div class="cell markdown" id="hJWhR3W8ayZC">
<p>Попробуем объединить бустинг и бэгинг. Давайте</p>
<p>1) в качестве базовой модели брать не дерево решений, а случайный лес
(из sklearn)</p>
<p>2) обучать N бустингов на бустрапированной выборке, а затем предикт
усреднять</p>
</div>
<div class="cell markdown" id="XgbcCqq9ayZC">
<p>Попробуйте обе этих стратегии на данных из прошлого задания.
Получилось ли улучшить качество? Почему?</p>
</div>
<div class="cell code" data-execution_count="756" data-collapsed="true"
id="TWN37SmUayZC" data-jupyter="{&quot;outputs_hidden&quot;:true}">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>my_clf <span class="op">=</span> MyGradientBoostingClassifier(<span class="st">&#39;LogLoss&#39;</span>, <span class="fl">0.2</span>, <span class="dv">50</span>, <span class="dv">1</span>, <span class="dv">1</span>, max_depth<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>my_clf.fit(X_train, y_train, RandomForestRegressor)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> my_clf.predict(X_test)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="757"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
data-collapsed="true" id="Z_SfiAwSayZC"
data-jupyter="{&quot;outputs_hidden&quot;:true}"
data-outputId="8c82d8c0-571c-4d9a-8ad6-30469925f4af">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>accuracy_score(y_pred<span class="op">=</span>my_clf.predict(X_test), y_true<span class="op">=</span>y_test)</span></code></pre></div>
<div class="output execute_result" data-execution_count="757">
<pre><code>0.8694282945736435</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="758"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:67,&quot;referenced_widgets&quot;:[&quot;643f80de25b14050988d49bce8f1e8a4&quot;,&quot;60e90d7ac95d40c8971a69c200033659&quot;,&quot;3b7bdca472324da09d83a68d0ced1a8a&quot;,&quot;a4cefd03ea9b42cdbb3bd273f68e7427&quot;,&quot;425efab48082430ebee11d28a2e59df0&quot;,&quot;15bf0cf052a84cd09043216cf0da1be5&quot;,&quot;175f4d4294184a069cffff73e947af91&quot;,&quot;7f8ca0e9eb2e477ea75178ddf855bfe7&quot;,&quot;8338e6fab1524b87a37717bc6a77cd9b&quot;,&quot;bccdee7987534a5aa7a3085ced106825&quot;,&quot;63eb16f78f51453b9b270315270d2c65&quot;]}"
id="q-0zVNpkfWyE" data-outputId="56793460-41f3-4974-ba60-9f3f249d8412">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> <span class="bu">len</span>(X_train)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>idxs <span class="op">=</span> np.arange(size)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>bootstrap_samples <span class="op">=</span> [np.random.choice(idxs, size<span class="op">=</span>size, replace<span class="op">=</span><span class="va">True</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">40</span>)]</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>accs <span class="op">=</span> []</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> sample <span class="kw">in</span> tqdm(bootstrap_samples):</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    X_sample <span class="op">=</span> X_train[sample]</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    y_sample <span class="op">=</span> y_train[sample]</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    my_clf <span class="op">=</span> MyGradientBoostingClassifier(<span class="st">&#39;LogLoss&#39;</span>, <span class="fl">0.2</span>, <span class="dv">80</span>, <span class="dv">1</span>, <span class="dv">1</span>, max_depth<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    my_clf.fit(X_sample, y_sample, DecisionTreeRegressor)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    accs.append(accuracy_score(y_pred<span class="op">=</span>my_clf.predict(X_test), y_true<span class="op">=</span>y_test))</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>np.mean(accs)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb32"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;643f80de25b14050988d49bce8f1e8a4&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output execute_result" data-execution_count="758">
<pre><code>0.8632873062015504</code></pre>
</div>
</div>
<div class="cell markdown" id="urCUdQKUrM1C">
<p>Точность получилось улучшить. В первом случае точность улучшилась за
счет того, что мы берем модель, которая позволяет нашему алгоритму
быстрее сходиться.</p>
<p>Во втором случае получается улучшить точность за счет того, что мы
обучаем несколько моделей на различных наборах данных и общая точность
алгоритма улучшается.</p>
</div>
<section id="умная-инициализация-1-балл" class="cell markdown"
data-collapsed="true" id="jfTYpNZcayZC"
data-jupyter="{&quot;outputs_hidden&quot;:true}">
<h2>Умная инициализация (1 балл)</h2>
<p>Попробуйте брать в качестве инициализации бустинга не константу, а
какой-то алгоритм и уже от его предикта стартовать итерации бустинга.
Попробуйте разные модели из sklearn: линейные модели, рандом форест,
svm..</p>
<p>Получилось ли улучшить качество? Почему?</p>
</section>
<div class="cell code" data-execution_count="27"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:212,&quot;referenced_widgets&quot;:[&quot;9f9c68459e6d43da911e80cbffa75440&quot;,&quot;5e9df109878a4256bd0e0d51db87984b&quot;,&quot;0d006a3168ce4c2b9eb3bec9bac19aab&quot;,&quot;4fe59dc468554d6496e8e47eef90ad8d&quot;,&quot;fed5102d7a604cea8543662110db8996&quot;,&quot;d99314160fb34a52ad32067c66cb5bb4&quot;,&quot;cc01c086325d4fbf9f5765138bba4a49&quot;,&quot;49e765394da641a3aa9a413f5d28ca1f&quot;,&quot;3994f513fdd443a9ad7bd905f9c260cd&quot;,&quot;079c37758b1c41e3a2a7563c25ed95e6&quot;,&quot;0ae3af9722d64d0ebfbed5b97819d0e6&quot;]}"
data-collapsed="true" id="DOyyAdFtayZC"
data-jupyter="{&quot;outputs_hidden&quot;:true}"
data-outputId="e51f001c-2ba2-4c26-ae2e-82fb580d0e1f">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingClassifier</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>models_list <span class="op">=</span> [LogisticRegression,</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>               KNeighborsClassifier,</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>               GradientBoostingClassifier]</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>accs <span class="op">=</span> []</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model <span class="kw">in</span> tqdm(models_list):</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    my_clf <span class="op">=</span> MyGradientBoostingClassifier(<span class="st">&#39;LogLoss&#39;</span>, <span class="fl">0.2</span>, <span class="dv">80</span>, <span class="dv">1</span>, <span class="dv">1</span>, max_depth<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>    my_clf.fit(X_train, y_train, DecisionTreeRegressor, init_model<span class="op">=</span>model)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>    accs.append(accuracy_score(y_pred<span class="op">=</span>my_clf.predict(X_test), y_true<span class="op">=</span>y_test))</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb35"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;9f9c68459e6d43da911e80cbffa75440&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="28"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="cu0E_S4kvAUB" data-outputId="c210fd53-7338-478e-ddd6-73f1e0f64196">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(accs)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[0.8599806201550387, 0.8645833333333334, 0.8561046511627907]
</code></pre>
</div>
</div>
<div class="cell markdown" id="x2tErqhPvtn6">
<p>Получилось улучшить качество с аналогичными параметрами, так как
изначально нашл алгоритм стартует из более выгодной точки, а точнее из
какого-то приближения, которое было получено при помощи init_model.</p>
</div>
<section id="фидбек-бесценно" class="cell markdown" id="6AG9E_wfayZC">
<h2>Фидбек (бесценно)</h2>
</section>
<div class="cell markdown" id="e_nf8m_layZC">
<ul>
<li>Какие аспекты обучения ансамблей Вам показались непонятными? Какое
место стоит дополнительно объяснить?</li>
</ul>
<p>Возможно стоит дополнительно объяснить классификацию при помощи
градиентного бустинга. Изначально было не совсем понятно, как выполнять
домашнее задание</p>
<p>На помощь пришли вот эти 2 статьи:</p>
<ul>
<li><p><a
href="https://scikit-learn.org/stable/modules/ensemble.html#id10"
class="uri">https://scikit-learn.org/stable/modules/ensemble.html#id10</a></p></li>
<li><p><a href="https://habr.com/ru/companies/ods/articles/327250/"
class="uri">https://habr.com/ru/companies/ods/articles/327250/</a></p></li>
</ul>
</div>
<section id="ваш-ответ-здесь" class="cell markdown" id="Lcc_faAEayZC">
<h3>Ваш ответ здесь</h3>
</section>
<div class="cell markdown" id="iJKUAWRJayZC">
<ul>
<li>Здесь Вы можете оставить отзыв о этой домашней работе или о всем
курсе.</li>
</ul>
</div>
<section id="ваш-отзыв-здесь" class="cell markdown" id="aU2iaJuuayZC">
<h3>ВАШ ОТЗЫВ ЗДЕСЬ</h3>
</section>
<div class="cell code" data-collapsed="true" id="aZ7IO0ZPayZC"
data-jupyter="{&quot;outputs_hidden&quot;:true}">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div class="cell code" data-collapsed="true" id="BOKFHb0jayZC"
data-jupyter="{&quot;outputs_hidden&quot;:true}">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
